"""Tier 3 AI íŒë‹¨ â€” Opusë¡œ "ë„ˆì²˜ëŸ¼ ë´¤ì„ ë•Œ" ì‹œê·¸ë„ ìƒì„±.

ì…ë ¥: Tier 2 ìˆ˜ì§‘ + Intelligence + ìœ ì € í˜„ì¬ ìƒíƒœ
ì¶œë ¥: ë§¤ë§¤ ì‹œê·¸ë„ (direction, reasoning, counter_argument, confidence, stop_loss)
      ë˜ëŠ” ììœ¨ ë¸Œë¦¬í•‘
"""

from __future__ import annotations

import json
import logging
from datetime import datetime, timezone
from typing import Any

from sqlalchemy.ext.asyncio import AsyncSession
from telegram import Bot

from src.bot.keyboards import signal_feedback
from src.config import PRO_DAILY_SIGNAL_LIMIT
from src.db.models import ChatMessage, Signal, User, UserTrigger
from src.intelligence.episode import build_intelligence_context, create_episode
from src.llm.client import llm_client
from src.llm.prompts import SIGNAL_JUDGE_PROMPT

logger = logging.getLogger(__name__)


async def judge_signal(
    session: AsyncSession,
    user: User,
    collected_data: dict[str, Any],
    trigger: UserTrigger,
    bot: Bot,
) -> Signal | None:
    """Tier 3 AI íŒë‹¨ â†’ ì‹œê·¸ë„ ìƒì„± + ì „ì†¡.

    Args:
        session: DB ì„¸ì…˜
        user: ìœ ì € ê°ì²´
        collected_data: Tier 2 ìˆ˜ì§‘ ê²°ê³¼
        trigger: ë°œë™ëœ íŠ¸ë¦¬ê±°
        bot: Telegram Bot

    Returns:
        ìƒì„±ëœ Signal ê°ì²´ ë˜ëŠ” None (ìƒí•œ ì´ˆê³¼ ë“±)
    """
    # ì‹œê·¸ë„ ìƒí•œ ì²´í¬ (Pro: ì¼ 5íšŒ)
    if not _check_signal_limit(user):
        try:
            await bot.send_message(
                chat_id=user.telegram_id,
                text=f"ì˜¤ëŠ˜ ì‹œê·¸ë„ {PRO_DAILY_SIGNAL_LIMIT}íšŒ ë‹¤ ì¼ì–´. ë‚´ì¼ ë¦¬ì…‹!",
            )
        except Exception:
            pass
        logger.info("ì‹œê·¸ë„ ìƒí•œ ì´ˆê³¼: user=%s", user.telegram_id)
        return None

    # Intelligence ì»¨í…ìŠ¤íŠ¸ êµ¬ì¶•
    intel_ctx = await build_intelligence_context(session, user)
    symbol = collected_data.get("symbol") or "UNKNOWN"

    # Tier 2 ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ì •ë¦¬
    data_text = _format_collected_data(collected_data)

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ì¡°ë¦½
    prompt = SIGNAL_JUDGE_PROMPT.format(
        symbol=symbol,
        trigger_description=trigger.description or "",
        collected_data=data_text,
        intelligence_context=intel_ctx["intelligence_context"],
        principles=intel_ctx["principles"],
        positions=intel_ctx["positions"],
    )

    # Opus í˜¸ì¶œ
    try:
        resp = await llm_client.signal_judge(
            system=prompt,
            messages=[{
                "role": "user",
                "content": f"íŠ¸ë¦¬ê±° ë°œë™: {trigger.description}\n\nìˆ˜ì§‘ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ íŒë‹¨í•´ì¤˜.",
            }],
            max_tokens=2048,
        )
        raw = resp.text.strip()
        logger.info(
            "ì‹œê·¸ë„ íŒë‹¨ LLM: in=%d (cache_read=%d), out=%d",
            resp.input_tokens, resp.cache_read_tokens, resp.output_tokens,
        )
    except Exception:
        logger.error("ì‹œê·¸ë„ íŒë‹¨ LLM í˜¸ì¶œ ì‹¤íŒ¨", exc_info=True)
        return None

    # ì‘ë‹µ íŒŒì‹±
    parsed = _parse_judge_response(raw)

    # Signal DB ì €ì¥
    signal = Signal(
        user_id=user.id,
        signal_type=parsed["signal_type"],
        content=parsed["content"],
        reasoning=parsed["reasoning"],
        counter_argument=parsed.get("counter_argument"),
        confidence=parsed["confidence"],
        confidence_style=parsed.get("confidence_style"),
        confidence_history=parsed.get("confidence_history"),
        confidence_market=parsed.get("confidence_market"),
        symbol=symbol,
        direction=parsed.get("direction"),
        stop_loss=parsed.get("stop_loss"),
    )
    session.add(signal)

    # ì¼ì¼ ì‹œê·¸ë„ ì¹´ìš´íŠ¸ ì¦ê°€
    user.daily_signal_count = (user.daily_signal_count or 0) + 1
    await session.flush()

    # ì‹œê·¸ë„ ë©”ì‹œì§€ í¬ë§·
    text = _format_signal_message(parsed, symbol)

    # DBì— assistant ë©”ì‹œì§€ ì €ì¥
    session.add(ChatMessage(
        user_id=user.id,
        role="assistant",
        content=text,
        message_type="text",
        intent="signal_trigger",
        metadata_={"signal_id": signal.id},
    ))
    await session.flush()

    # ì°¨íŠ¸ ì´ë¯¸ì§€ ì „ì†¡ (ìˆìœ¼ë©´)
    chart_png = collected_data.get("chart_png")

    try:
        if chart_png:
            from io import BytesIO

            await bot.send_photo(
                chat_id=user.telegram_id,
                photo=BytesIO(chart_png),
                caption=f"ğŸ“¸ {symbol} ì°¨íŠ¸",
            )

        # ì‹œê·¸ë„ í…ìŠ¤íŠ¸ + í”¼ë“œë°± í‚¤ë³´ë“œ ì „ì†¡
        await bot.send_message(
            chat_id=user.telegram_id,
            text=text,
            reply_markup=signal_feedback(),
        )
    except Exception:
        logger.error("ì‹œê·¸ë„ ì „ì†¡ ì‹¤íŒ¨: user=%s", user.telegram_id, exc_info=True)

    # ì—í”¼ì†Œë“œ ìƒì„±
    await create_episode(
        session,
        user,
        episode_type="signal",
        user_action=f"ì‹œê·¸ë„: {symbol} {parsed.get('direction', 'watch')}",
        embedding_text=f"{symbol} {parsed['reasoning'][:300]}",
        reasoning=parsed["reasoning"],
        auto_collect_market=True,
    )

    logger.info(
        "ì‹œê·¸ë„ ìƒì„±: user=%s, %s %s (conf=%.0f%%)",
        user.telegram_id, symbol,
        parsed.get("direction", "watch"),
        parsed["confidence"] * 100,
    )
    return signal


# ------------------------------------------------------------------
# ì‹œê·¸ë„ ìƒí•œ ì²´í¬
# ------------------------------------------------------------------


def _check_signal_limit(user: User) -> bool:
    """ì¼ì¼ ì‹œê·¸ë„ ìƒí•œ ì²´í¬ + ë¦¬ì…‹."""
    now = datetime.now(timezone.utc)

    # ë‚ ì§œê°€ ë°”ë€Œì—ˆìœ¼ë©´ ë¦¬ì…‹
    if user.daily_signal_reset_at:
        if user.daily_signal_reset_at.date() < now.date():
            user.daily_signal_count = 0
            user.daily_signal_reset_at = now
    else:
        user.daily_signal_reset_at = now

    return (user.daily_signal_count or 0) < PRO_DAILY_SIGNAL_LIMIT


# ------------------------------------------------------------------
# ì‘ë‹µ íŒŒì‹±
# ------------------------------------------------------------------


def _parse_confidence(raw_conf: Any) -> dict[str, float | None]:
    """confidenceë¥¼ íŒŒì‹± â€” 3ì¶• dict ë˜ëŠ” ë‹¨ì¼ float ëª¨ë‘ ì²˜ë¦¬.

    Returns:
        confidence: overall ê°€ì¤‘í‰ê· 
        confidence_style/history/market: ê° ì¶• (ì—†ìœ¼ë©´ None)
    """
    if isinstance(raw_conf, dict):
        style = float(raw_conf.get("style_match", 0.5))
        history = float(raw_conf.get("historical_similar", 0.5))
        market = float(raw_conf.get("market_context", 0.5))
        overall = style * 0.3 + history * 0.3 + market * 0.4
        return {
            "confidence": overall,
            "confidence_style": style,
            "confidence_history": history,
            "confidence_market": market,
        }
    val = float(raw_conf) if raw_conf else 0.5
    if val > 1:
        val = val / 100
    return {
        "confidence": val,
        "confidence_style": None,
        "confidence_history": None,
        "confidence_market": None,
    }


def _parse_judge_response(raw: str) -> dict[str, Any]:
    """Opus ì‘ë‹µì„ êµ¬ì¡°í™”ëœ ì‹œê·¸ë„ë¡œ íŒŒì‹±.

    OpusëŠ” JSON ë¸”ë¡ ë˜ëŠ” ìì—°ì–´ë¡œ ì‘ë‹µí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì–‘ìª½ ëª¨ë‘ ì²˜ë¦¬.
    """
    import re

    # JSON ë¸”ë¡ ì¶”ì¶œ ì‹œë„
    json_match = re.search(r"```json\s*(\{.*?\})\s*```", raw, re.DOTALL)
    if json_match:
        try:
            data = json.loads(json_match.group(1))
            conf = _parse_confidence(data.get("confidence", 0.5))
            return {
                "signal_type": data.get("signal_type", "trade_signal"),
                "direction": data.get("direction", "watch"),
                "reasoning": data.get("reasoning", raw[:500]),
                "counter_argument": data.get("counter_argument"),
                "stop_loss": data.get("stop_loss"),
                "content": _build_content(data, raw),
                **conf,
            }
        except (json.JSONDecodeError, ValueError):
            pass

    # ìì—°ì–´ íŒŒì‹± fallback
    direction = "watch"
    for d, keywords in [
        ("long", ["ë¡±", "long", "ë§¤ìˆ˜", "ì§„ì…"]),
        ("short", ["ìˆ", "short", "ë§¤ë„"]),
        ("exit", ["ì²­ì‚°", "exit", "íƒˆì¶œ"]),
    ]:
        if any(kw in raw.lower() for kw in keywords):
            direction = d
            break

    # confidence ì¶”ì¶œ
    conf_match = re.search(r"í™•ì‹ ë„[:\s]*(\d+)", raw)
    confidence = float(conf_match.group(1)) / 100 if conf_match else 0.5
    if confidence > 1:
        confidence = confidence / 100

    # counter_argument ì¶”ì¶œ
    counter = None
    counter_match = re.search(r"(?:ë°˜ëŒ€|âš ï¸).*?[:ï¼š]\s*(.+?)(?:\n\n|\Z)", raw, re.DOTALL)
    if counter_match:
        counter = counter_match.group(1).strip()[:500]

    # stop_loss ì¶”ì¶œ
    sl_match = re.search(r"ì†ì ˆ[:\s]*(.+?)(?:\n|$)", raw)
    stop_loss = sl_match.group(1).strip() if sl_match else None

    # ë¸Œë¦¬í•‘ì¸ì§€ ì‹œê·¸ë„ì¸ì§€
    is_briefing = any(kw in raw.lower() for kw in ["ë¸Œë¦¬í•‘", "briefing", "ì°¸ê³ "])
    signal_type = "briefing" if is_briefing else "trade_signal"

    return {
        "signal_type": signal_type,
        "direction": direction,
        "reasoning": raw[:1000],
        "counter_argument": counter,
        "confidence": confidence,
        "confidence_style": None,
        "confidence_history": None,
        "confidence_market": None,
        "stop_loss": stop_loss,
        "content": raw[:2000],
    }


def _build_content(data: dict[str, Any], raw: str) -> str:
    """JSON ë°ì´í„°ì—ì„œ content í•„ë“œ ìƒì„±."""
    parts = []
    if data.get("reasoning"):
        parts.append(data["reasoning"])
    if data.get("counter_argument"):
        parts.append(f"ë°˜ëŒ€ ê·¼ê±°: {data['counter_argument']}")
    return "\n\n".join(parts) if parts else raw[:1000]


# ------------------------------------------------------------------
# ì‹œê·¸ë„ ë©”ì‹œì§€ í¬ë§·
# ------------------------------------------------------------------


def _confidence_bar(label: str, value: float) -> str:
    """Unicode ë§‰ëŒ€ ê·¸ë˜í”„ í•œ ì¤„ ìƒì„±."""
    filled = round(value * 10)
    bar = "â–ˆ" * filled + "â–‘" * (10 - filled)
    return f"  {label}  {bar}  {value*100:.0f}%"


def _format_signal_message(parsed: dict[str, Any], symbol: str) -> str:
    """ì‹œê·¸ë„ì„ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ë¡œ í¬ë§· â€” 3ì¶• í™•ì‹ ë„ ë°” ê·¸ë˜í”„."""
    direction = parsed.get("direction", "watch")
    dir_emoji = {
        "long": "ğŸŸ¢ ë¡±",
        "short": "ğŸ”´ ìˆ",
        "exit": "ğŸšª ì²­ì‚°",
        "watch": "ğŸ‘€ ê´€ë§",
    }.get(direction, "ğŸ‘€ ê´€ë§")

    overall = parsed.get("confidence", 0.5)

    lines = [f"ğŸ¯ {symbol} {dir_emoji} ìƒí™©"]
    lines.append("")
    lines.append(f"ğŸ“Š íŒë‹¨ ê·¼ê±°:\n{parsed.get('reasoning', '')[:800]}")

    counter = parsed.get("counter_argument") or "ë°˜ëŒ€ ì‹œë‚˜ë¦¬ì˜¤ë„ í•­ìƒ ì¡´ì¬í•´. ë¦¬ìŠ¤í¬ ê´€ë¦¬ í•„ìˆ˜."
    lines.append(f"\nâš ï¸ ë°˜ëŒ€ ê·¼ê±°:\n{counter[:400]}")

    lines.append(f"\nğŸ“ í™•ì‹ ë„: {overall*100:.0f}%")

    style = parsed.get("confidence_style")
    history = parsed.get("confidence_history")
    market = parsed.get("confidence_market")
    if style is not None and history is not None and market is not None:
        lines.append(_confidence_bar("ìŠ¤íƒ€ì¼ ë§¤ì¹­", style))
        lines.append(_confidence_bar("ìœ ì‚¬ ê³¼ê±° ", history))
        lines.append(_confidence_bar("ì‹œì¥ ë§¥ë½ ", market))

    stop = parsed.get("stop_loss")
    if stop:
        lines.append(f"\nğŸ›‘ ì†ì ˆ: {stop}")

    lines.append("\nì–´ë–»ê²Œ ìƒê°í•´?")
    lines.append("\nâš ï¸ TRADEFORKëŠ” ë§¤ë§¤ë¥¼ ëŒ€í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ìµœì¢… íŒë‹¨ì€ ë³¸ì¸ì˜ ëª«ì…ë‹ˆë‹¤.")

    return "\n".join(lines)


# ------------------------------------------------------------------
# ìˆ˜ì§‘ ë°ì´í„° í…ìŠ¤íŠ¸ í¬ë§·
# ------------------------------------------------------------------


def _format_collected_data(collected: dict[str, Any]) -> str:
    """Tier 2 ìˆ˜ì§‘ ë°ì´í„°ë¥¼ LLM í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜."""
    parts: list[str] = []

    # Base ë°ì´í„°
    base = collected.get("base_data", {})
    if base:
        base_lines = []
        for k, v in base.items():
            if isinstance(v, (dict, list)):
                base_lines.append(f"- {k}: {json.dumps(v, ensure_ascii=False, default=str)[:300]}")
            else:
                base_lines.append(f"- {k}: {v}")
        parts.append("## Base ë°ì´í„°\n" + "\n".join(base_lines[:15]))

    # API ë°ì´í„°
    api = collected.get("api_data", {})
    if api:
        api_lines = []
        for k, v in api.items():
            if isinstance(v, (dict, list)):
                api_lines.append(f"- {k}: {json.dumps(v, ensure_ascii=False, default=str)[:300]}")
            else:
                api_lines.append(f"- {k}: {v}")
        parts.append("## ì™¸ë¶€ API\n" + "\n".join(api_lines[:10]))

    # ê²€ìƒ‰ ë°ì´í„°
    search = collected.get("search_data")
    if search:
        parts.append(f"## ì›¹ ê²€ìƒ‰\n{search[:1500]}")

    return "\n\n".join(parts) if parts else "ìˆ˜ì§‘ ë°ì´í„° ì—†ìŒ"
